{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The SegNet VGG 16 model notebook\n",
        "cited from:\n",
        "\n",
        "@article{badrinarayanan2017segnet,\n",
        "  title={Segnet: A deep convolutional encoder-decoder architecture for image segmentation},\n",
        "  author={Badrinarayanan, Vijay and Kendall, Alex and Cipolla, Roberto},\n",
        "  journal={IEEE transactions on pattern analysis and machine intelligence},\n",
        "  volume={39},\n",
        "  number={12},\n",
        "  pages={2481--2495},\n",
        "  year={2017},\n",
        "  publisher={IEEE}\n",
        "}"
      ],
      "metadata": {
        "id": "P8_S97KWV4KT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "epBC0-GsUUlk"
      },
      "outputs": [],
      "source": [
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import pickle\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"6DUZXUzEElvb164kQwwY\")\n",
        "project = rf.workspace(\"pingworkspace\").project(\"txlpbc-v2-vnadh\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"voc\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OcMDiU9G2-bV",
        "outputId": "7f8560a7-ee13-4b3e-ee5f-a277ca09f3a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.2.0-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.6.15)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.0.2)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.2.1)\n",
            "Collecting pillow-heif<2 (from roboflow)\n",
            "  Downloading pillow_heif-1.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting pillow-avif-plugin<2 (from roboflow)\n",
            "  Downloading pillow_avif_plugin-1.5.2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.4.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.58.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.2)\n",
            "Downloading roboflow-1.2.0-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp311-cp311-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_heif-1.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m124.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: pillow-avif-plugin, filetype, python-dotenv, pillow-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.11.0.86\n",
            "    Uninstalling opencv-python-headless-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-headless-4.11.0.86\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pillow-avif-plugin-1.5.2 pillow-heif-1.0.0 python-dotenv-1.1.1 roboflow-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cv2",
                  "idna"
                ]
              },
              "id": "d6703283c84e498ea17cc098d0dea000"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = 'txlpbc-v2-1/'\n",
        "\n",
        "train_path = \"txlpbc-v2-1/train/\"\n",
        "\n",
        "valid_path = \"txlpbc-v2-1/valid/\"\n",
        "\n",
        "test_path = \"txlpbc-v2-1/test/\"\n",
        "\n",
        "# train_file = data_path + \"train.p\"\n",
        "# valid_file = data_path + \"val.p\"\n",
        "# test_file = data_path + \"test.p\""
      ],
      "metadata": {
        "id": "I-k_AQZjUhw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "\n",
        "def class_name_to_id(class_name):\n",
        "    class_map = {\n",
        "        'PC': 0,  # Replace with actual class names\n",
        "        'RBC': 1,\n",
        "        'WBC': 2,\n",
        "    }\n",
        "    return class_map.get(class_name, -1)  # Default to -1 for unknown classes\n",
        "\n",
        "def parse_xml(xml_file, image_shape, num_classes=3):\n",
        "    # Initialize mask (2D) where 0 represents background\n",
        "    mask = np.zeros(image_shape[:2], dtype=np.uint8)\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    for obj in root.findall('object'):\n",
        "        class_name = obj.find('name').text\n",
        "        class_id = class_name_to_id(class_name)  # Assuming function to map class names to ids\n",
        "\n",
        "        polygon = obj.find('polygon')\n",
        "        if polygon is not None:\n",
        "            # Extract polygon points\n",
        "            points = []\n",
        "            i = 1\n",
        "            while True:\n",
        "                x = polygon.find(f'x{i}')\n",
        "                y = polygon.find(f'y{i}')\n",
        "                if x is None or y is None:\n",
        "                    break  # Exit if no more points\n",
        "                points.append([int(float(x.text)), int(float(y.text))])\n",
        "                i += 1\n",
        "\n",
        "            if points:\n",
        "                # Convert points list to a proper format for OpenCV (Nx2 array)\n",
        "                points = np.array(points, dtype=np.int32)\n",
        "                points = points.reshape((-1, 1, 2))  # Reshape to required format for fillPoly\n",
        "\n",
        "                # Fill the polygon on the mask with the class ID\n",
        "                cv2.fillPoly(mask, [points], class_id)\n",
        "\n",
        "        else:\n",
        "            # Fallback to bounding box if polygon is not available\n",
        "            bbox = obj.find('bndbox')\n",
        "            if bbox is not None:\n",
        "                xmin = int(bbox.find('xmin').text)\n",
        "                ymin = int(bbox.find('ymin').text)\n",
        "                xmax = int(bbox.find('xmax').text)\n",
        "                ymax = int(bbox.find('ymax').text)\n",
        "\n",
        "                # Draw class_id into the bounding box area of the mask\n",
        "                mask[ymin:ymax, xmin:xmax] = class_id\n",
        "\n",
        "    return mask\n",
        "\n",
        "def make_dataset(image_dir, num_classes=3):\n",
        "    images = []\n",
        "    masks = []\n",
        "\n",
        "    for filename in os.listdir(image_dir):\n",
        "        if filename.endswith('.jpg'):\n",
        "            image_path = os.path.join(image_dir, filename)\n",
        "            xml_path = os.path.join(image_dir, filename[:-4] + '.xml')  # Use the same filename for the XML\n",
        "\n",
        "            # Read and resize the image to 224x224\n",
        "            image = cv2.resize(cv2.imread(image_path), (224, 224))  # Assuming input size is 224x224\n",
        "            images.append(image)\n",
        "\n",
        "            # Parse the corresponding XML file to create the mask\n",
        "            mask = parse_xml(xml_path, image.shape, num_classes)\n",
        "            mask = cv2.resize(mask, (224, 224), interpolation=cv2.INTER_NEAREST)\n",
        "            masks.append(mask)\n",
        "\n",
        "    images = np.array(images)\n",
        "    masks = np.array(masks)\n",
        "    return images, masks\n",
        "\n",
        "\n",
        "# Directory containing your dataset\n",
        "# image_dir = 'txlpbc-v2-1/train'\n",
        "# X_train, y_train = make_dataset(image_dir, num_classes=3)\n"
      ],
      "metadata": {
        "id": "-DIXFmwULI92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = make_dataset(train_path)\n",
        "X_val, y_val = make_dataset(valid_path)\n",
        "X_test, y_test = make_dataset(test_path)"
      ],
      "metadata": {
        "id": "C5PR7tbhUw7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.concatenate([X_train, X_val])\n",
        "y_train = np.concatenate([y_train, y_val])"
      ],
      "metadata": {
        "id": "P2ldR7x6UyZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "VEZSAkPDYLeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.gridspec import GridSpec\n",
        "from random import randint, sample\n",
        "ranidx = randint(0, len(y_train))\n",
        "gs = GridSpec(4,4)\n",
        "plt.figure(dpi=100)\n",
        "for i in range(3):\n",
        "    plt.subplot(gs[i]), plt.imshow(y_train[ranidx][:,:]), plt.axis('off')\n",
        "\n",
        "plt.subplot(gs[3]), plt.imshow(X_train[ranidx]), plt.axis('off')"
      ],
      "metadata": {
        "id": "bcPmavv9Uz6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "#RBC = [128,128,128]\n",
        "RBC = [128,0,0]\n",
        "# Building = [128,0,0]\n",
        "# Pole = [192,192,128]\n",
        "# Road_marking = [255,69,0]\n",
        "# Road = [128,64,128]\n",
        "# Pavement = [60,40,222]\n",
        "# WBC = [128,128,0]\n",
        "WBC = [60,40,222]\n",
        "# SignSymbol = [192,128,128]\n",
        "# Fence = [64,64,128]\n",
        "PC = [64,0,128]\n",
        "# Pedestrian = [64,64,0]\n",
        "# Bicyclist = [0,128,192]\n",
        "Unlabelled = [0,0,0]\n",
        "\n",
        "#label_colours = np.array([RBC, WBC, PC, Unlabelled])\n",
        "label_colours = np.array([Unlabelled,RBC, WBC, PC])\n",
        "def visualize(temp, plot=True):\n",
        "    r = temp.copy()\n",
        "    g = temp.copy()\n",
        "    b = temp.copy()\n",
        "\n",
        "    for l in [0, 1, 2]:\n",
        "        r[temp==l]=label_colours[l,0]\n",
        "        g[temp==l]=label_colours[l,1]\n",
        "        b[temp==l]=label_colours[l,2]\n",
        "\n",
        "    rgb = np.zeros((temp.shape[0], temp.shape[1], 3))\n",
        "    rgb[:,:,0] = (r/255.0)#[:,:,0]\n",
        "    rgb[:,:,1] = (g/255.0)#[:,:,1]\n",
        "    rgb[:,:,2] = (b/255.0)#[:,:,2]\n",
        "    if plot:\n",
        "        plt.imshow(rgb)\n",
        "    else:\n",
        "        return rgb\n",
        "\n",
        "# randsample = sample(range(0,len(pred)), 4)\n",
        "randsample = [0, 1, 2, 3]\n",
        "gs = GridSpec(3,5)\n",
        "plt.figure(dpi=200)\n",
        "\n",
        "for i in range(4):\n",
        "    ground_truth_path = y_test[randsample[i]]  # Path to XML ground truth file\n",
        "    ground_truth_labels = parse_xml_label(ground_truth_path)\n",
        "    ground_truth_visual = visualize(ground_truth_labels, plot=False)\n",
        "    plt.subplot(gs[10 + i]), plt.imshow(ground_truth_visual), plt.axis('off')\n",
        "\n",
        "    plt.subplot(gs[i]), plt.imshow(X_test[randsample[i]]), plt.axis('off')\n",
        "    plt.subplot(gs[5+i]), plt.imshow(output), plt.axis('off')\n",
        "    #plt.subplot(gs[10+i]), plt.imshow(out_test), plt.axis('off')"
      ],
      "metadata": {
        "id": "dhA-n3nLP-FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape[1:] )"
      ],
      "metadata": {
        "id": "bRxejtK2P6in"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 3\n",
        "input_shape = X_train.shape[1:] #(480,480,3)\n",
        "smooth = 1.\n",
        "nproc = 8"
      ],
      "metadata": {
        "id": "4luShNVkU8oH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --user keras"
      ],
      "metadata": {
        "id": "EvjUSFpKM0Ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Activation, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Create SegNet model for 3 classes\n",
        "def segnet(input_shape=(224, 224, 3), num_classes=3):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Encoder (same as VGG16)\n",
        "    x = Conv2D(64, (3, 3), padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Decoder\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Final layer\n",
        "    outputs = Conv2D(num_classes, (1, 1), padding='same')(x)\n",
        "    outputs = Activation('softmax')(outputs)  # Use softmax for multi-class classification\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "model = segnet(input_shape=(224, 224, 3), num_classes=3)\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "id": "XFoj5CoCUQK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=8,\n",
        "                    epochs=200,\n",
        "                    shuffle=True)"
      ],
      "metadata": {
        "id": "H4uc8HIMVgbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "EFyoEJ_Kgo_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history.keys()"
      ],
      "metadata": {
        "id": "XnhLJAQBVikw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "8BFcQMvqVjqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "# plt.plot(history.history['val_acc'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j-mtAXjoVlOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_test, verbose=1)\n",
        "\n",
        "ranidx = randint(0, len(y_test))\n",
        "gs = GridSpec(1,12)\n",
        "plt.figure(dpi=200)\n",
        "for i in range(12):\n",
        "    plt.subplot(gs[i]), plt.imshow(pred[ranidx][:,:], cmap='jet'), plt.axis('off')\n",
        "\n",
        "plt.figure(dpi=200)\n",
        "for i in range(12):\n",
        "    plt.subplot(gs[i]), plt.imshow(y_test[ranidx][:,:],cmap='jet'), plt.axis('off')\n",
        "\n",
        "plt.figure(),plt.imshow(X_test[ranidx]), plt.axis('off')"
      ],
      "metadata": {
        "id": "emoVRQP6Vn9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# refer from : https://github.com/preddy5/segnet/blob/master/Segnet.ipynb\n",
        "#RBC = [128,128,128]\n",
        "RBC = [128,0,0]\n",
        "# Building = [128,0,0]\n",
        "# Pole = [192,192,128]\n",
        "# Road_marking = [255,69,0]\n",
        "# Road = [128,64,128]\n",
        "# Pavement = [60,40,222]\n",
        "# WBC = [128,128,0]\n",
        "WBC = [60,40,222]\n",
        "# SignSymbol = [192,128,128]\n",
        "# Fence = [64,64,128]\n",
        "PC = [64,0,128]\n",
        "# Pedestrian = [64,64,0]\n",
        "# Bicyclist = [0,128,192]\n",
        "Unlabelled = [0,0,0]\n",
        "\n",
        "#label_colours = np.array([RBC, WBC, PC, Unlabelled])\n",
        "label_colours = np.array([Unlabelled,RBC, WBC, PC])\n",
        "def visualize(temp, plot=True):\n",
        "    r = temp.copy()\n",
        "    g = temp.copy()\n",
        "    b = temp.copy()\n",
        "\n",
        "    for l in [0, 1, 2]:\n",
        "        r[temp==l]=label_colours[l,0]\n",
        "        g[temp==l]=label_colours[l,1]\n",
        "        b[temp==l]=label_colours[l,2]\n",
        "\n",
        "    rgb = np.zeros((temp.shape[0], temp.shape[1], 3))\n",
        "    rgb[:,:,0] = (r/255.0)#[:,:,0]\n",
        "    rgb[:,:,1] = (g/255.0)#[:,:,1]\n",
        "    rgb[:,:,2] = (b/255.0)#[:,:,2]\n",
        "    if plot:\n",
        "        plt.imshow(rgb)\n",
        "    else:\n",
        "        return rgb\n",
        "\n",
        "# randsample = sample(range(0,len(pred)), 4)\n",
        "randsample = [0, 1, 2, 3]\n",
        "gs = GridSpec(3,5)\n",
        "plt.figure(dpi=200)\n",
        "\n",
        "for i in range(4):\n",
        "    output = visualize(np.argmax(pred[randsample[i]],axis=2).reshape((224,224)), plot=False)\n",
        "    #out_test = visualize(np.argmax(y_test[randsample[i]],axis=2).reshape((224,224)), plot=False)\n",
        "\n",
        "    plt.subplot(gs[i]), plt.imshow(X_test[randsample[i]]), plt.axis('off')\n",
        "    plt.subplot(gs[5+i]), plt.imshow(output), plt.axis('off')\n",
        "    #plt.subplot(gs[10+i]), plt.imshow(out_test), plt.axis('off')"
      ],
      "metadata": {
        "id": "tn9Ne5twVwM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "\n",
        "# Color mappings\n",
        "RBC = [128, 0, 0]\n",
        "WBC = [60, 40, 222]\n",
        "PC = [64, 0, 128]\n",
        "Unlabelled = [0, 0, 0]\n",
        "label_colours = np.array([Unlabelled, RBC, WBC, PC])\n",
        "\n",
        "# Visualization function\n",
        "def visualize(temp, plot=True):\n",
        "    r = temp.copy()\n",
        "    g = temp.copy()\n",
        "    b = temp.copy()\n",
        "\n",
        "    for l in [0, 1, 2, 3]:  # Updated to include all labels in label_colours\n",
        "        r[temp == l] = label_colours[l, 0]\n",
        "        g[temp == l] = label_colours[l, 1]\n",
        "        b[temp == l] = label_colours[l, 2]\n",
        "\n",
        "    rgb = np.zeros((temp.shape[0], temp.shape[1], 3))\n",
        "    rgb[:, :, 0] = r / 255.0\n",
        "    rgb[:, :, 1] = g / 255.0\n",
        "    rgb[:, :, 2] = b / 255.0\n",
        "    if plot:\n",
        "        plt.imshow(rgb)\n",
        "    else:\n",
        "        return rgb\n",
        "\n",
        "# Sample data\n",
        "randsample = [0, 1, 2, 3]\n",
        "gs = GridSpec(3, 5)\n",
        "plt.figure(dpi=200)\n",
        "\n",
        "for i in range(4):\n",
        "    # Display original image\n",
        "    plt.subplot(gs[i]), plt.imshow(X_test[randsample[i]]), plt.axis('off')\n",
        "\n",
        "    # Display model prediction\n",
        "    output = visualize(np.argmax(pred[randsample[i]], axis=2).reshape((224, 224)), plot=False)\n",
        "    plt.subplot(gs[5 + i]), plt.imshow(output), plt.axis('off')\n",
        "\n",
        "    # Display ground truth from y_test\n",
        "    ground_truth_visual = visualize(y_test[randsample[i]], plot=False)\n",
        "    plt.subplot(gs[10 + i]), plt.imshow(ground_truth_visual), plt.axis('off')\n"
      ],
      "metadata": {
        "id": "8WEVVRm9Tgfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('txlpbc-v2-1/blood_cell_segnet_model.h5')"
      ],
      "metadata": {
        "id": "kVQje-XafNc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xWqhFcNQpa4n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}